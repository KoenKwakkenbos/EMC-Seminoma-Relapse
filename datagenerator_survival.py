import os
import glob
import random
import tensorflow as tf
import numpy as np
import cv2
from concurrent.futures import ThreadPoolExecutor
from tensorflow.keras.applications.resnet50 import preprocess_input


def _make_riskset(time: np.ndarray) -> np.ndarray:
    """Compute mask that represents each sample's risk set.

    Parameters
    ----------
    time : np.ndarray, shape=(n_samples,)
        Observed event time sorted in descending order.

    Returns
    -------
    risk_set : np.ndarray, shape=(n_samples, n_samples)
        Boolean matrix where the `i`-th row denotes the
        risk set of the `i`-th instance, i.e. the indices `j`
        for which the observer time `y_j >= y_i`.
    """
    assert time.ndim == 1, "expected 1D array"

    # sort in descending order
    o = np.argsort(-time, kind="mergesort")
    n_samples = len(time)
    risk_set = np.zeros((n_samples, n_samples), dtype=np.bool_)
    for i_org, i_sort in enumerate(o):
        ti = time[i_sort]
        k = i_org
        while k < n_samples and ti == time[o[k]]:
            k += 1
        risk_set[i_sort, o[:k]] = True
    return risk_set


class Datagen(tf.keras.utils.Sequence):
    """
    A generator class that yields batches of preprocessed image data and corresponding outcome
    labels.

    Parameters:
    - slide_list (list): A list of patient IDs corresponding to the slides from which tiles
      are to be extracted.
    - outcome_list (list): A list of binary outcome labels corresponding to the slide_list
      patients.
    - tile_size (int): The desired width and height in pixels of the square tiles to be extracted
      from each slide.
    - batch_size (int): The number of samples to generate per batch.
    - train (bool): A boolean indicating whether the generator is being used for training. If
      True, image augmentation will be applied to the generated batches.
    - imagenet (bool, optional): Whether to preprocess images for use with pre-trained Imagenet
      models. Default is False.
    """
    def __init__(self, slide_list, outcome_list, time_list, tile_size, tile_path, batch_size=32, train=False, imagenet=False):
        self.slide_list = slide_list
        self.pat_outcome_list = outcome_list
        self.pat_time_list = time_list
        self.tile_size = tile_size
        self.tile_path = tile_path
        self.batch_size = batch_size
        self.train = train
        self.imagenet = imagenet
        self.tile_list = []
        self.tile_outcome_list = []
        self.tile_time_list = []
        self.slide_tile_list = []
        self.minority_class_label = 1
        # for patient in self.slide_list:
        #     for root, _, files in os.walk(os.path.join(tile_path, str(patient))):
        #         for file in files:
        #             self.tile_list.append(os.path.join(root, file))
        #             self.tile_outcome_list.append(self.pat_outcome_list[patient])

        for patient in self.slide_list:
            for file in glob.glob(f'{self.tile_path}/**/{patient}*.png'):
                self.tile_list.append(file)
                self.tile_outcome_list.append(self.pat_outcome_list[patient])
                self.tile_time_list.append(self.pat_time_list[patient])
                self.slide_tile_list.append(patient) # --> or purely on slide level?

        # Oversampling
        # minority_class = np.where(np.array(self.tile_outcome_list) == self.minority_class_label)[0]

        # self.tile_list.extend([self.tile_list[i] for i in minority_class])
        # self.tile_outcome_list.extend([self.tile_outcome_list[i] for i in minority_class])
        self.slide_tile_list = np.array(self.slide_tile_list)

        self.on_epoch_end()

    def __len__(self):
        """
        Returns the number of batches that can be generated by this instance of the Datagen
        class.
        """
        return int(np.ceil(len(self.indexes) / self.batch_size))

    def _process_image(self, tile):
        """
        Loads, normalizes, and applies data augmentation to an image tile.
        
        Parameters:
        - tile (str): The file path of the tile image to be processed.
        
        Returns:
        - A normalized and augmented image.
        """
        image = cv2.imread(tile)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # CHECK IF THIS IS REMOVED!!

        # image_norm = self._normalize_image(image)

        # ----------------------------------------

        image_norm = image / 255.

        if self.train:
            image_norm = self._augment_image(image_norm)

        return image_norm

    def __getitem__(self, idx):
        """
        Generates a batch of preprocessed image data and corresponding outcome labels.
        
        Parameters:
        - idx (int): The batch index.
        
        Returns:
        - A tuple containing a batch of image data and a batch of outcome labels.
        """
        indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]

        # normalization removed, still necessary?
        # with ThreadPoolExecutor(max_workers=32) as executor:
        #     X = list(executor.map(lambda tile: self._process_image(tile), [self.tile_list[k] for k in indexes]))

        X = np.array([self._process_image(self.tile_list[k]) for k in indexes])
        event = np.array([self.tile_outcome_list[k] for k in indexes])
        time = np.array([self.tile_time_list[k] for k in indexes])

        labels = {
            "label_event": event.astype(np.int32),
            "label_time": time.astype(np.float32),
            "label_riskset": _make_riskset(time)
        }

        return X, labels

    def _augment_image(self, img):
        """
        Applies random transformations to an image.

        Parameters:
        - image (numpy array): An image represented as a numpy array with shape (height, width, channels).

        Returns:
        - The augmented image as a numpy array with the same shape as the input image.
        """
        if random.random() < 0.75:
            rot = random.choice([cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_180, cv2.ROTATE_90_COUNTERCLOCKWISE])
            img = cv2.rotate(img, rot)

        if random.random() < 0.5:
            flip = random.choice([-1, 0, 1])
            img = cv2.flip(img, flip)

        return img

    def on_epoch_end(self):
        """
        Method called at the end of every epoch. Applies shuffling and resets the
        batch index.
        """
        self.indexes = np.arange(len(self.tile_list))
        if self.train:
            np.random.shuffle(self.indexes)

        self.__len__()


class DatagenMILSurv(Datagen):
    def __init__(self, slide_list, outcome_list, time_list, tile_size, tile_path, batch_size=32, train=True, imagenet=False):
        # Call parent class's initialization
        super().__init__(slide_list, outcome_list, time_list, tile_size, tile_path, batch_size, train, imagenet)

    def topk_dataset(self, idx):
        """
        Set the indexes to be used for the next batch.

        Parameters:
        - idx (list): List of indexes to be used for the next training step (the top indexes).
        """

        # CHECK IF CORRECT:
        # If shuffeled, we need index of indexes

        self.indexes = self.indexes[np.array(idx)]
        if self.train:
            np.random.shuffle(self.indexes)

        self.__len__()

    # def on_epoch_end(self):
    #     """
    #     Reset the indexes back to the entire dataset for the next inference pass.
    #     """
    #     self.indexes = np.arange(len(self.tile_list))

        # Shuffle multiple lists the same way??
