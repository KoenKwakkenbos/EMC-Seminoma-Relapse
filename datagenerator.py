"""
File containing the three datagenerator classes used in the research.

The base class is the datagenerator used in fully-supervised learning.
Batches of tiles are generated along with the outcome label (X, y). The
datagenerator used in the autoencoder experiments inherits most of its
properties from the base class, but outputs the same tile twice (X, X),
as its target is reconstructing the image.
Finally, the MIL datagenerator has an additional function that sets the
tiles for training to the top-10 tiles per slide. This resets after each
epoch.

Author: Koen Kwakkenbos
(k.kwakkenbos@student.tudelft.nl/k.kwakkenbos@gmail.com)
Version: 1.0
Date: Feb 2022
"""

import os
import glob
import random
import tensorflow as tf
import numpy as np
import cv2
from concurrent.futures import ThreadPoolExecutor
from tensorflow.keras.applications.resnet50 import preprocess_input


class Datagen(tf.keras.utils.Sequence):
    """
    A generator class that yields batches of preprocessed image data and corresponding outcome
    labels.

    Parameters:
    - slide_list (list): A list of patient IDs corresponding to the slides from which tiles
      are to be extracted.
    - outcome_list (list): A list of binary outcome labels corresponding to the slide_list
      patients.
    - tile_size (int): The desired width and height in pixels of the square tiles to be extracted
      from each slide.
    - batch_size (int): The number of samples to generate per batch.
    - train (bool): A boolean indicating whether the generator is being used for training. If
      True, image augmentation will be applied to the generated batches.
    - imagenet (bool, optional): Whether to preprocess images for use with pre-trained Imagenet
      models. Default is False.
    """
    def __init__(self, slide_list, outcome_list, clinical_vars, tile_size, tile_path, batch_size=32, train=False, imagenet=False):
        self.slide_list = slide_list
        self.pat_outcome_list = outcome_list
        self.pat_clinical_vars = clinical_vars
        self.tile_size = tile_size
        self.tile_path = tile_path
        self.batch_size = batch_size
        self.train = train
        self.imagenet = imagenet
        self.tile_list = []
        self.tile_outcome_list = []
        self.tile_clinical_list = []
        self.minority_class_label = 1
        # for patient in self.slide_list:
        #     for root, _, files in os.walk(os.path.join(tile_path, str(patient))):
        #         for file in files:
        #             self.tile_list.append(os.path.join(root, file))
        #             self.tile_outcome_list.append(self.pat_outcome_list[patient])

        for patient in self.slide_list:
            for file in glob.glob(f'{self.tile_path}/**/{patient}*.png'):
                    self.tile_list.append(file)
                    self.tile_outcome_list.append(self.pat_outcome_list[patient])
                    self.tile_clinical_list.append(self.pat_clinical_vars.loc[patient])
    
        # Oversampling
        # if self.train:
        #     minority_class = np.where(np.array(self.tile_outcome_list) == self.minority_class_label)[0]

        #     self.tile_list.extend([self.tile_list[i] for i in minority_class])
        #     self.tile_outcome_list.extend([self.tile_outcome_list[i] for i in minority_class])
        #     self.tile_outcome_list.extend([self.tile_outcome_list[i] for i in minority_class])
    
        self.on_epoch_end()


    def __len__(self):
        """
        Returns the number of batches that can be generated by this instance of the Datagen
        class.
        """
        return int(np.floor(len(self.tile_list) / self.batch_size))

    def _process_image(self, tile):
        """
        Loads, normalizes, and applies data augmentation to an image tile.
        
        Parameters:
        - tile (str): The file path of the tile image to be processed.
        
        Returns:
        - A normalized and augmented image.
        """
        image = cv2.imread(tile)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # CHECK IF THIS IS REMOVED!!

        # image_norm = self._normalize_image(image)

        # ----------------------------------------

        if self.train:
            image = self._augment_image(image)
        
        image_norm = image / 255.
        
        return image_norm


    def __getitem__(self, idx):
        """
        Generates a batch of preprocessed image data and corresponding outcome labels.
        
        Parameters:
        - idx (int): The batch index.
        
        Returns:
        - A tuple containing a batch of image data and a batch of outcome labels.
        """
        indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]

        # normalization removed, still necessary?
        # with ThreadPoolExecutor(max_workers=32) as executor:
        #     X = list(executor.map(lambda tile: self._process_image(tile), [self.tile_list[k] for k in indexes]))

        X = np.array([self._process_image(self.tile_list[k]) for k in indexes])
        y = np.array([self.tile_outcome_list[k] for k in indexes])

        return X, y

    # Adapted from: https://github.com/schaugf/HEnorm_python
    def _normalize_image(self, img, Io=240, alpha=1, beta=0.15):
        ''' Normalize staining appearence of H&E stained images

        Input:
            I: RGB input image
            Io: (optional) transmitted light intensity

        Output:
            Inorm: normalized image
            H: hematoxylin image
            E: eosin image

        Reference:
            A method for normalizing histology slides for quantitative analysis. M.
            Macenko et al., ISBI 2009
        '''

        HERef = np.array([[0.5626, 0.2159],
                        [0.7201, 0.8012],
                        [0.4062, 0.5581]])

        maxCRef = np.array([1.9705, 1.0308])

        # define height and width of image
        h, w, _ = img.shape

        # reshape image
        img = img.reshape((-1, 3))

        # calculate optical density
        OD = -np.log((img.astype(np.float)+1)/Io)

        # remove transparent pixels
        ODhat = OD[~np.any(OD < beta, axis=1)]

        # compute eigenvectors
        _, eigvecs = np.linalg.eigh(np.cov(ODhat.T))

        #project on the plane spanned by the eigenvectors corresponding to the two
        # largest eigenvalues
        That = ODhat.dot(eigvecs[:, 1:3])

        phi = np.arctan2(That[:, 1],That[:, 0])

        minPhi = np.percentile(phi, alpha)
        maxPhi = np.percentile(phi, 100-alpha)

        vMin = eigvecs[:, 1:3].dot(np.array([(np.cos(minPhi), np.sin(minPhi))]).T)
        vMax = eigvecs[:, 1:3].dot(np.array([(np.cos(maxPhi), np.sin(maxPhi))]).T)

        # a heuristic to make the vector corresponding to hematoxylin first and the
        # one corresponding to eosin second
        if vMin[0] > vMax[0]:
            HE = np.array((vMin[:, 0], vMax[:, 0])).T
        else:
            HE = np.array((vMax[:, 0], vMin[:, 0])).T

        # rows correspond to channels (RGB), columns to OD values
        Y = np.reshape(OD, (-1, 3)).T

        # determine concentrations of the individual stains
        C = np.linalg.lstsq(HE,Y, rcond=None)[0]

        # normalize stain concentrations
        maxC = np.array([np.percentile(C[0, :], 99), np.percentile(C[1, :],99)])
        tmp = np.divide(maxC,maxCRef)
        C2 = np.divide(C,tmp[:, np.newaxis])

        # recreate the image using reference mixing matrix
        Inorm = np.multiply(Io, np.exp(-HERef.dot(C2)))
        Inorm[Inorm > 255] = 254
        Inorm = np.reshape(Inorm.T, (h, w, 3)).astype(np.uint8)

        if self.imagenet:
            Inorm = preprocess_input(Inorm)
        else:
            Inorm = cv2.normalize(Inorm, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)

        return Inorm


    def _augment_image(self, img):
        """
        Applies random transformations to an image.

        Parameters:
        - image (numpy array): An image represented as a numpy array with shape (height, width, channels).

        Returns:
        - The augmented image as a numpy array with the same shape as the input image.
        """
        if random.random() < 0.75:
            rot = random.choice([cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_180, cv2.ROTATE_90_COUNTERCLOCKWISE])
            img = cv2.rotate(img, rot)

        if random.random() < 0.75:
            flip = random.choice([-1, 0, 1])
            img = cv2.flip(img, flip)

        if random.random() < 75:
            img = cv2.convertScaleAbs(img, alpha=random.uniform(0.8, 1.2), beta=random.uniform(0.8, 1.2))

        return img


    def on_epoch_end(self):
        """
        Method called at the end of every epoch. Applies shuffling and resets the
        batch index.
        """
        self.indexes = np.arange(len(self.tile_list))
        if self.train:
            np.random.shuffle(self.indexes)


class AEDatagen(Datagen):
    """
    A generator class that yields batches of preprocessed image data and corresponding outcome labels.
    Inherits the variables and functions from the Datagen class.
    """
    def __getitem__(self, idx):
        """
        Generates a batch of preprocessed image data.
        
        Parameters:
        - idx (int): The batch index.
        
        Returns:
        - A tuple containing the same batch of image data twice for the autoencoder.
        """
        indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]

        # Uses multiple threads to speed up loading and processing tiles. The normalization step is the bottle-
        # neck.
        with ThreadPoolExecutor(max_workers=32) as executor:
            X = list(executor.map(lambda tile: self._process_image(tile), [self.tile_list[k] for k in indexes]))

        X = np.array(X)

        return X, X


class MILdatagen(Datagen):
    """
    A generator class that yields batches of preprocessed image data and corresponding outcome labels.

    Parameters:
    - slide_list (list): List of slide names (directory names).
    - outcome_list (dict): Dictionary of patient outcomes (0 or 1) with patient names (directory names) as keys.
    - tile_size (int): Size of the square tiles to be extracted from the whole slide images.
    - batch_size (int, optional): Number of samples per batch. Default is 32.
    - train (bool, optional: Whether the generator is used for training. Default is False.
    - imagenet (bool, optional): Whether to preprocess images for use with pre-trained Imagenet models. Default
      is False.
    """
    def __init__(self, slide_list, outcome_list, tile_size, tile_path, batch_size=32, train=False, imagenet=False):
        self.slide_list = slide_list
        self.pat_outcome_list = outcome_list
        self.tile_size = tile_size
        self.tile_path = tile_path
        self.batch_size = batch_size
        self.train = train
        self.tile_list = []
        self.slide_tile_list = []
        self.tile_outcome_list = []
        self.imagenet = imagenet

        for patient in self.slide_list:
            for root, _, files in os.walk(os.path.join(tile_path, str(patient))):
                for file in files:
                    self.tile_list.append(os.path.join(root, file))
                    self.tile_outcome_list.append(self.pat_outcome_list[patient])
                    self.slide_tile_list.append(os.path.basename(root))

        self.on_epoch_end()


    def topk_dataset(self, idx):
        """
        Set the indexes to be used for the next batch.

        Parameters:
        - idx (list): List of indexes to be used for the next training step (the top indexes).
        """
        self.indexes = np.array(idx)
        if self.train:
            np.random.shuffle(self.indexes)


    def on_epoch_end(self):
        """
        Reset the indexes back to the entire dataset for the next inference pass.
        """
        self.indexes = np.arange(len(self.tile_list))
